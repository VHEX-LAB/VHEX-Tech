{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VHEX-LAB/VHEX-Tech/blob/main/iris-server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsGFriSmWVRX"
      },
      "source": [
        "# Save/Load models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJCE7bHlMmTn",
        "outputId": "f5d663a1-5698-4c11-a2b5-a27161b1172d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "model = LogisticRegression(random_state=0, max_iter=1000)\n",
        "model.fit(X, y)  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqeOGjIKOipo",
        "outputId": "dd6f9bf4-83bb-42f9-d840-99554887e999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(X)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7wTus0qROLC"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3KOMgLRRV2Q"
      },
      "source": [
        "model.predict([X[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J90eAwTfUeIc"
      },
      "source": [
        "joblib.dump(model, \"iris.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNbrLxCOVowh"
      },
      "source": [
        "model = joblib.load(\"iris.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFzVbzRJWevZ"
      },
      "source": [
        "# Serve models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qig0N36MWMSL"
      },
      "source": [
        "!pip install flask-ngrok -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy8BHeRKWu5g"
      },
      "source": [
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok  # To use flask server in colab\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "  \n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"hello\"\n",
        "    \n",
        "app.run() # Use gunicorn in production evironment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PtO75XHQa27H"
      },
      "source": [
        "from flask import Flask, request\n",
        "from flask_ngrok import run_with_ngrok  # To use flask server in colab\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "  \n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def hello():\n",
        "    data = request.get_json(True)\n",
        "    sepal_length = data[\"sepal_length\"]\n",
        "    sepal_width = data[\"sepal_width\"]\n",
        "    petal_length = data[\"petal_length\"]\n",
        "    petal_width = data[\"petal_width\"]\n",
        "\n",
        "    input = [sepal_length, sepal_width, petal_length, petal_width]\n",
        "    species = model.predict([input])\n",
        "    return str(species[0])\n",
        "    \n",
        "app.run() # Use gunicorn in production evironment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBNh3U-gq4Iu"
      },
      "source": [
        "# Cache(Single machine level)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YGLZwmUt5S_C"
      },
      "source": [
        "from flask import Flask, request\n",
        "from flask_ngrok import run_with_ngrok  # To use flask server in colab\n",
        "\n",
        "\n",
        "cache = {}\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "  \n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def hello():\n",
        "    data = request.get_json(True)\n",
        "    sepal_length = data[\"sepal_length\"]\n",
        "    sepal_width = data[\"sepal_width\"]\n",
        "    petal_length = data[\"petal_length\"]\n",
        "    petal_width = data[\"petal_width\"]\n",
        "\n",
        "    key = (sepal_length, sepal_width, petal_length, petal_width)\n",
        "    if key in cache:\n",
        "        print(\"cached\")\n",
        "        return cache[key]\n",
        "\n",
        "    input = list(key)\n",
        "    species = model.predict([input])\n",
        "    cache[key] = str(species[0])\n",
        "    return str(species[0])\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWG8FKn_q8wT"
      },
      "source": [
        "# High availability(Single machine Level)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zayGepWM6xw9"
      },
      "source": [
        "%%writefile app.py\n",
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from flask import Flask, request\n",
        "from flask_ngrok import run_with_ngrok  # To use flask server in colab\n",
        "\n",
        "model = joblib.load(\"iris.model\")\n",
        "cache = {}\n",
        "\n",
        "app = Flask(__name__)\n",
        "  \n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def hello():\n",
        "    data = request.get_json(True)\n",
        "    sepal_length = data[\"sepal_length\"]\n",
        "    sepal_width = data[\"sepal_width\"]\n",
        "    petal_length = data[\"petal_length\"]\n",
        "    petal_width = data[\"petal_width\"]\n",
        "\n",
        "    key = (sepal_length, sepal_width, petal_length, petal_width)\n",
        "    if key in cache:\n",
        "        print(\"cached\")\n",
        "        return cache[key]\n",
        "\n",
        "    input = list(key)\n",
        "    species = model.predict([input])\n",
        "    cache[key] = str(species[0])\n",
        "    return str(species[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxevGYQ7rFKp"
      },
      "source": [
        "!pip install gunicorn -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z8zbMNBrMLc"
      },
      "source": [
        "!gunicorn app:app -w 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzz8uiuo71nf"
      },
      "source": [
        "!nohup gunicorn app:app -w 4 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XI1umSx85bH"
      },
      "source": [
        "!ps --forest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgACX4Av98qM"
      },
      "source": [
        "!curl 127.0.0.1:8000 \\\n",
        "-H 'Context-Type: application/json' \\\n",
        "--data-raw '{\"sepal_length\": 1.0,\"sepal_width\": 2.0,\"petal_length\": 2.0,\"petal_width\": 1.0}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5xZBsDH87XT"
      },
      "source": [
        "!kill  336"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt40aAaU0fNP"
      },
      "source": [
        "# BentoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXVUfxblsICO"
      },
      "source": [
        "!pip install bentoml -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPb_9yOE0rNC"
      },
      "source": [
        "%%writefile bento_service.py\n",
        "import pandas as pd\n",
        "\n",
        "from bentoml import env, artifacts, api, BentoService\n",
        "from bentoml.adapters import DataframeInput\n",
        "from bentoml.frameworks.sklearn import SklearnModelArtifact\n",
        "\n",
        "@env(infer_pip_packages=True)\n",
        "@artifacts([SklearnModelArtifact('model')])\n",
        "class IrisClassifier(BentoService):\n",
        "    @api(input=DataframeInput(), batch=True)\n",
        "    def predict(self, df: pd.DataFrame):\n",
        "        return self.artifacts.model.predict(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBw0ZfYeBpVL"
      },
      "source": [
        "from bento_service import IrisClassifier\n",
        "\n",
        "iris_classifier_service = IrisClassifier()\n",
        "iris_classifier_service.pack('model', model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4gmmctQB2qf"
      },
      "source": [
        "iris_classifier_service.predict([[1.1, 2.3, 2.3, 3.4]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ifN9nJjCI9q"
      },
      "source": [
        "iris_classifier_service.start_dev_server()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0zPNgG2CVCt"
      },
      "source": [
        "!curl 127.0.0.1:5000/predict \\\n",
        "-H 'Context-Type: application/json' \\\n",
        "--data-raw '[{\"sepal_length\": 1.0,\"sepal_width\": 2.0,\"petal_length\": 2.0,\"petal_width\": 1.0}]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_gNo_dqDcBV"
      },
      "source": [
        "iris_classifier_service.stop_dev_server()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmgDW119Ckau"
      },
      "source": [
        "iris_classifier_service.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RCvQttGDBJI"
      },
      "source": [
        "!bentoml serve IrisClassifier:latest --run-with-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqcbkmddDY9b"
      },
      "source": [
        "!bentoml serve-gunicorn IrisClassifier:latest --workers 4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}